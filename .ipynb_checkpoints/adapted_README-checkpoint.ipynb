{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src=\"logo.jpg\", width=150, ALIGN=\"left\", border=20>\n",
    "<center>\n",
    "<h1>Final project</h1>\n",
    "<br>This code was tested with <br>\n",
    "Python 2.7.13 | Anaconda 4.3.1 (https://anaconda.org/)<br>\n",
    "<i> Adapted for Chalab by Isabelle Guyon from original code of Balázs Kégl</i> <br>\n",
    "<a href=\"http://www.datascience-paris-saclay.fr\">Paris Saclay Center for Data Science (CDS)</a>\n",
    "</center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The aim of this competition is to predict at best the sales by some stores. This notebook helps the users in the preparation of submissions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep this:\n",
    "model_dir = 'sample_code_submission/'          \n",
    "problem_dir = 'ingestion_program/'  \n",
    "score_dir = 'scoring_program/'\n",
    "from sys import path; path.append(model_dir); path.append(problem_dir); path.append(score_dir); \n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "<h2> Step 1: Exploratory data analysis </h2>\n",
    "Create a folder 'sample_data' and put the files in Data1 (available by github) inside it. This is the folder with the data and solutions for the training data. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data:\r\n",
      "store_feat.name   store_public.info  store_train.data\t   store_valid.data\r\n",
      "store_label.name  store_test.data    store_train.solution\r\n",
      "\r\n",
      "sample_data_iris:\r\n",
      "iris_feat.name\t  iris_test.data      iris_train.solution\r\n",
      "iris_label.name   iris_test.solution  iris_valid.data\r\n",
      "iris_public.info  iris_train.data     iris_valid.solution\r\n"
     ]
    }
   ],
   "source": [
    "datadir = 'sample_data'              # Change this to the directory where you put the input data\n",
    "dataname = 'store'\n",
    "!ls $datadir*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we load the data as a \"pandas\" data frame, so we can use \"pandas\" and \"seaborn\" built in functions to explore the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading sample_data/store_test from AutoML format\n",
      "Number of examples = 203441\n",
      "Number of features = 8\n"
     ]
    }
   ],
   "source": [
    "from data_io import read_as_df\n",
    "data = read_as_df(datadir  + '/' + dataname)                # The data are loaded as a Pandas Data Frame\n",
    "target_name = data.columns.values[-1]                       # The last column is the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1084</td>\n",
       "      <td>7</td>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>218</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-06-26</td>\n",
       "      <td>613</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-03-27</td>\n",
       "      <td>621</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>957</td>\n",
       "      <td>7</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>852</td>\n",
       "      <td>6</td>\n",
       "      <td>2013-09-14</td>\n",
       "      <td>315</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Customers  Open  Promo StateHoliday  \\\n",
       "0   1084          7  2014-12-28          0     0      0            0   \n",
       "1    218          5  2015-06-26        613     1      0            0   \n",
       "2    289          3  2013-03-27        621     1      1            0   \n",
       "3    957          7  2013-04-14          0     0      0            0   \n",
       "4    852          6  2013-09-14        315     1      0            0   \n",
       "\n",
       "   SchoolHoliday  \n",
       "0              1  \n",
       "1              0  \n",
       "2              1  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>712046.000000</td>\n",
       "      <td>712046.000000</td>\n",
       "      <td>712046.000000</td>\n",
       "      <td>712046.000000</td>\n",
       "      <td>712046.000000</td>\n",
       "      <td>712046.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>558.409264</td>\n",
       "      <td>3.999173</td>\n",
       "      <td>633.279063</td>\n",
       "      <td>0.829910</td>\n",
       "      <td>0.381151</td>\n",
       "      <td>0.178504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>321.906650</td>\n",
       "      <td>1.997958</td>\n",
       "      <td>465.108051</td>\n",
       "      <td>0.375712</td>\n",
       "      <td>0.485670</td>\n",
       "      <td>0.382937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>558.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>838.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>837.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1115.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7388.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Store      DayOfWeek      Customers           Open  \\\n",
       "count  712046.000000  712046.000000  712046.000000  712046.000000   \n",
       "mean      558.409264       3.999173     633.279063       0.829910   \n",
       "std       321.906650       1.997958     465.108051       0.375712   \n",
       "min         1.000000       1.000000       0.000000       0.000000   \n",
       "25%       280.000000       2.000000     404.000000       1.000000   \n",
       "50%       558.000000       4.000000     609.000000       1.000000   \n",
       "75%       838.000000       6.000000     837.000000       1.000000   \n",
       "max      1115.000000       7.000000    7388.000000       1.000000   \n",
       "\n",
       "               Promo  SchoolHoliday  \n",
       "count  712046.000000  712046.000000  \n",
       "mean        0.381151       0.178504  \n",
       "std         0.485670       0.382937  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         1.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Building a predictive model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data with DataManager\n",
    "We reload the data with the AutoML DataManager class because this is more convenient.\n",
    "\n",
    "Note that we use `conv_to_num=False`, this means that categorical target values encoded in AutoML format with the 1-hot encoding are NOT converted to categorical labels (which is what scikit-learn assumes). Hence this conversion will need to be done before you call any scikit-learn model. Be aware that the variable 'date' is a string and the following is not going to work, unless the variable is transformed into a Float number, with a suitable transformation. Make this transformation before running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info file found : /home/kihansi/Projects/FinalProject_CertBigData/starting_kit/sample_data/store_public.info\n",
      "========= Reading sample_data/store_feat.type\n",
      "[+] Success in  0.00 sec\n",
      "========= Reading sample_data/store_train.data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-b3f3b464998d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#D = DataManager(dataname, datadir, replace_missing=True, conv_to_num=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatadir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/FinalProject_CertBigData/starting_kit/ingestion_program/data_manager.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, basename, input_dir, verbose, replace_missing, filter_features, max_samples)\u001b[0m\n\u001b[1;32m     76\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                                 \u001b[0;31m#if True: return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                                 \u001b[0mXtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadData\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_train.data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplace_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                                 \u001b[0mYtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadLabel\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_train.solution'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                                 \u001b[0mmax_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/FinalProject_CertBigData/starting_kit/ingestion_program/data_manager.py\u001b[0m in \u001b[0;36mloadData\u001b[0;34m(self, filename, verbose, replace_missing)\u001b[0m\n\u001b[1;32m    129\u001b[0m                                 \u001b[0mdata_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'dense'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdata_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sparse'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdata_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sparse_binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdata_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_binary_sparse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'format'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feat_num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                                 \u001b[0;31m# INPORTANT: when we replace missing values we double the number of variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/FinalProject_CertBigData/starting_kit/ingestion_program/data_io.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(filename, nbr_features, verbose)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;31m#    data_matrix[i, 2] = datetime.strptime(data_matrix[i, 2], '%Y-%m-%d').timestamp()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mdata_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datetime64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mdata_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0mdata_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unique values: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'a'"
     ]
    }
   ],
   "source": [
    "from data_manager import DataManager\n",
    "#D = DataManager(dataname, datadir, replace_missing=True, conv_to_num=False)\n",
    "D = DataManager(dataname, datadir, replace_missing=True, verbose=True)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a predictive model\n",
    "We provide an example of predictive model (for classification or regression) in the `sample_code_submission/` directory. It is a quite stupid model: it makes constant predictions. Replace it with your own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import model\n",
    "??model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "<h3>Create the model</h3>\n",
    "Create an instance of the model (run the constructor) \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = model()   \n",
    "trained_model_name = model_dir + dataname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Training:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = D.data['X_train']\n",
    "Y_train = D.data['Y_train']\n",
    "\n",
    "if not(M.is_trained):               # No need to train if model already trained\n",
    "    M.fit(X_train, Y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_train = M.predict(D.data['X_train']) # Optional, not really needed to test on taining examples\n",
    "Y_hat_valid = M.predict(D.data['X_valid'])\n",
    "Y_hat_test = M.predict(D.data['X_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring the results\n",
    "### Load the challenge metric\n",
    "<b>The metric chosen for your challenge</b> is identified in the \"metric.txt\" file found in the `scoring_function/` directory. We use here the `mse_metric` metric (an example of organizer-supplied metric found in `my_metric.py`), which computes the mean-square-error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_installed_distributions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9cb588d7eb53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'metric.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmetric_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlibscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscoring_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/FinalProject_CertBigData/starting_kit/scoring_program/libscores.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mswrite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetcwd\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpip\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_installed_distributions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mglob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplatform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_installed_distributions'"
     ]
    }
   ],
   "source": [
    "with open(score_dir + 'metric.txt', 'r') as f:\n",
    "    metric_name = f.readline().strip()\n",
    "import libscores, my_metric\n",
    "try:\n",
    "    scoring_function = getattr(libscores, metric_name)\n",
    "except:\n",
    "    scoring_function = getattr(my_metric, metric_name)\n",
    "print('Using scoring metric:', metric_name)\n",
    "??scoring_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training performance\n",
    "The participants posess target values (labels) only for training examples. We compute with the mse metric the training score, which should be zero for perfect predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Training score for the', metric_name, 'metric = %5.4f' % scoring_function(Y_train, Y_hat_train)\n",
    "print 'Ideal score for the', metric_name, 'metric = %5.4f' % scoring_function(Y_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "<H3> Cross-validation performance </H3>\n",
    "The participants do not have access to the labels Y_valid and Y_test to self-assess their validation and test performances. But training performance is not a good prediction of validation or test performance. We suggest to use a cross-validation. Using cross-validation, the training data is split into multiple training/test folds, which allows participants to self-assess their model during development. <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from numpy import zeros, mean\n",
    "# 3-fold cross-validation\n",
    "n = 3\n",
    "kf = KFold(n_splits=n)\n",
    "kf.get_n_splits(X_train)\n",
    "i=0\n",
    "scores = zeros(n)\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    Xtr, Xva = X_train[train_index], X_train[test_index]\n",
    "    Ytr, Yva = Y_train[train_index], Y_train[test_index]\n",
    "    M = model()\n",
    "    M.fit(Xtr, Ytr)\n",
    "    Yhat = M.predict(Xva)\n",
    "    scores[i] = scoring_function(Yva, Yhat)\n",
    "    print ('Fold', i+1, 'example metric = ', scores[i])\n",
    "    i=i+1\n",
    "print ('Average score = ', mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Making a submission\n",
    "\n",
    "## Unit testing\n",
    "\n",
    "A possibility to prepare a submission is the following one.  Modify the file <code>model.py</code> in the <code>sample_code_submission/</code> directory, then run this test to make sure everything works fine. The results of this program will be used on the server to test your submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdir = 'sample_result_submission'     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python $problem_dir/ingestion.py $datadir $outdir $problem_dir $model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preparing the submission\n",
    "\n",
    "To prepare the submission, you can run the command in the previous cell on the appropriate data (testing or validation data), and then zip the contents of `sample_result_submission/` (without the directory, and remember to remove the examples that are already there).\n",
    "\n",
    "However, it is not necessary to run the previous code to prepare a submission. The site for the submission checks the predicted results against the true labels, through the scoring function. It accepts any zip file conatining files with extension '.predict'. It is important however that the name of the file matches that of the data. Example: to submit labels for store_train.data, the zip file has to contain a file named store_train.predict, with the same structure of the ones in `sample_result_submission/`\n",
    "<b><span style=\"color:red\">Do NOT zip the data with your submissions</span></b>. After the submission you are given your score. If the result is close to zero, the prediction is good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
