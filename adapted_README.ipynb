{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src=\"logo.jpg\", width=150, ALIGN=\"left\", border=20>\n",
    "<center>\n",
    "<h1>Final project</h1>\n",
    "<br>This code was tested with <br>\n",
    "Python 2.7.13 | Anaconda 4.3.1 (https://anaconda.org/)<br>\n",
    "<i> Adapted for Chalab by Isabelle Guyon from original code of Balázs Kégl</i> <br>\n",
    "<a href=\"http://www.datascience-paris-saclay.fr\">Paris Saclay Center for Data Science (CDS)</a>\n",
    "</center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The aim of this competition is to predict at best the sales by some stores. This notebook helps the users in the preparation of submissions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep this:\n",
    "model_dir = 'sample_code_submission/'          \n",
    "problem_dir = 'ingestion_program/'  \n",
    "score_dir = 'scoring_program/'\n",
    "from sys import path; path.append(model_dir); path.append(problem_dir); path.append(score_dir); \n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "<h2> Step 1: Exploratory data analysis </h2>\n",
    "Create a folder 'sample_data' and put the files in Data1 (available by github) inside it. This is the folder with the data and solutions for the training data. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data:\r\n",
      "store_feat.name   store_public.info  store_train.data\t   store_valid.data\r\n",
      "store_label.name  store_test.data    store_train.solution\r\n",
      "\r\n",
      "sample_data_iris:\r\n",
      "iris_feat.name\t  iris_test.data      iris_train.solution\r\n",
      "iris_label.name   iris_test.solution  iris_valid.data\r\n",
      "iris_public.info  iris_train.data     iris_valid.solution\r\n"
     ]
    }
   ],
   "source": [
    "datadir = 'sample_data'              # Change this to the directory where you put the input data\n",
    "dataname = 'store'\n",
    "!ls $datadir*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we load the data as a \"pandas\" data frame, so we can use \"pandas\" and \"seaborn\" built in functions to explore the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading sample_data/store_train from AutoML format\n",
      "Number of examples = 712045\n",
      "Number of features = 8\n",
      "Number of classes = 1\n"
     ]
    }
   ],
   "source": [
    "from data_io import read_as_df\n",
    "data = read_as_df(datadir  + '/' + dataname)                # The data are loaded as a Pandas Data Frame\n",
    "target_name = data.columns.values[-1]                       # The last column is the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>625</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-11-06</td>\n",
       "      <td>641</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>293</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-07-16</td>\n",
       "      <td>877</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-01-23</td>\n",
       "      <td>561</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>676</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>1584</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>709</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-22</td>\n",
       "      <td>1477</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Customers  Open  Promo StateHoliday  \\\n",
       "0    625          3  2013-11-06        641     1      1            0   \n",
       "1    293          2  2013-07-16        877     1      1            0   \n",
       "2     39          4  2014-01-23        561     1      1            0   \n",
       "3    676          4  2013-09-26       1584     1      1            0   \n",
       "4    709          3  2014-01-22       1477     1      1            0   \n",
       "\n",
       "   SchoolHoliday target  \n",
       "0              0  Sales  \n",
       "1              1  Sales  \n",
       "2              0  Sales  \n",
       "3              0  Sales  \n",
       "4              0  Sales  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>712045.000000</td>\n",
       "      <td>712045.000000</td>\n",
       "      <td>712045.000000</td>\n",
       "      <td>712045.000000</td>\n",
       "      <td>712045.000000</td>\n",
       "      <td>712045.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>558.314199</td>\n",
       "      <td>4.000265</td>\n",
       "      <td>633.399958</td>\n",
       "      <td>0.830174</td>\n",
       "      <td>0.381519</td>\n",
       "      <td>0.178543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>321.898476</td>\n",
       "      <td>1.996580</td>\n",
       "      <td>464.360651</td>\n",
       "      <td>0.375480</td>\n",
       "      <td>0.485760</td>\n",
       "      <td>0.382970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>405.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>558.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>837.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>838.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1115.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5494.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Store      DayOfWeek      Customers           Open  \\\n",
       "count  712045.000000  712045.000000  712045.000000  712045.000000   \n",
       "mean      558.314199       4.000265     633.399958       0.830174   \n",
       "std       321.898476       1.996580     464.360651       0.375480   \n",
       "min         1.000000       1.000000       0.000000       0.000000   \n",
       "25%       280.000000       2.000000     405.000000       1.000000   \n",
       "50%       558.000000       4.000000     609.000000       1.000000   \n",
       "75%       837.000000       6.000000     838.000000       1.000000   \n",
       "max      1115.000000       7.000000    5494.000000       1.000000   \n",
       "\n",
       "               Promo  SchoolHoliday  \n",
       "count  712045.000000  712045.000000  \n",
       "mean        0.381519       0.178543  \n",
       "std         0.485760       0.382970  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         1.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Building a predictive model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data with DataManager\n",
    "We reload the data with the AutoML DataManager class because this is more convenient.\n",
    "\n",
    "Note that we use `conv_to_num=False`, this means that categorical target values encoded in AutoML format with the 1-hot encoding are NOT converted to categorical labels (which is what scikit-learn assumes). Hence this conversion will need to be done before you call any scikit-learn model. Be aware that the variable 'date' is a string and the following is not going to work, unless the variable is transformed into a Float number, with a suitable transformation. Make this transformation before running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info file found : /home/kihansi/Projects/FinalProject_CertBigData/starting_kit/sample_data/store_public.info\n",
      "filename= sample_data/store_train.data\n",
      "data_matrix [['625' '3' '2013-11-06' '641' '1' '1' '0' '0']\n",
      " ['293' '2' '2013-07-16' '877' '1' '1' '0' '1']\n",
      " ['39' '4' '2014-01-23' '561' '1' '1' '0' '0']]\n",
      "after:  [['625' '16015.0' '641' '1' '1' '0' '1' '0' '0' '0' '0' '0' '1' '0' '0'\n",
      "  '0' '0']\n",
      " ['293' '15902.0' '877' '1' '1' '1' '1' '0' '0' '0' '0' '1' '0' '0' '0'\n",
      "  '0' '0']\n",
      " ['39' '16093.0' '561' '1' '1' '0' '1' '0' '0' '0' '0' '0' '0' '1' '0'\n",
      "  '0' '0']]\n",
      "filename= sample_data/store_train.solution\n",
      "filename= sample_data/store_valid.data\n",
      "data_matrix [['731' '1' '2014-02-24' '920' '1' '0' '0' '0']\n",
      " ['293' '4' '2013-01-03' '754' '1' '0' '0' '1']\n",
      " ['650' '1' '2013-12-30' '785' '1' '0' '0' '1']]\n",
      "after:  [['731' '16125.0' '920' '1' '0' '0' '1' '0' '0' '0' '1' '0' '0' '0' '0'\n",
      "  '0' '0']\n",
      " ['293' '15708.0' '754' '1' '0' '1' '1' '0' '0' '0' '0' '0' '0' '1' '0'\n",
      "  '0' '0']\n",
      " ['650' '16069.0' '785' '1' '0' '1' '1' '0' '0' '0' '1' '0' '0' '0' '0'\n",
      "  '0' '0']]\n",
      "filename= sample_data/store_test.data\n",
      "data_matrix [['249' '5' '2014-12-19' '725' '1' '1' '0' '0']\n",
      " ['190' '4' '2013-02-28' '564' '1' '0' '0' '0']\n",
      " ['850' '3' '2013-06-05' '644' '1' '1' '0' '0']]\n",
      "after:  [['249' '16423.0' '725' '1' '1' '0' '1' '0' '0' '0' '0' '0' '0' '0' '1'\n",
      "  '0' '0']\n",
      " ['190' '15764.0' '564' '1' '0' '0' '1' '0' '0' '0' '0' '0' '0' '1' '0'\n",
      "  '0' '0']\n",
      " ['850' '15861.0' '644' '1' '1' '0' '1' '0' '0' '0' '0' '0' '1' '0' '0'\n",
      "  '0' '0']]\n",
      "DataManager : store\n",
      "info:\n",
      "\tusage = Sample dataset data\n",
      "\tname = wavestone\n",
      "\ttask = regression\n",
      "\ttarget_type = Numerical\n",
      "\tfeat_type = Numerical, String\n",
      "\tmetric = bac_metric\n",
      "\ttime_budget = 1200\n",
      "\tfeat_num = 8\n",
      "\ttarget_num = 1\n",
      "\tlabel_num = 1\n",
      "\ttrain_num = 712046\n",
      "\tvalid_num = 101722\n",
      "\ttest_num = 203441\n",
      "\thas_categorical = 0\n",
      "\thas_missing = 1\n",
      "\tis_sparse = 0\n",
      "\tformat = dense\n",
      "data:\n",
      "\tX_train = array(712045, 17)\n",
      "\tY_train = array(712045,)\n",
      "\tX_valid = array(101720, 17)\n",
      "\tX_test = array(203444, 17)\n",
      "feat_type:\tarray(8,)\n",
      "feat_idx:\tarray(0,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data_manager import DataManager\n",
    "#D = DataManager(dataname, datadir, replace_missing=True, conv_to_num=False)\n",
    "D = DataManager(dataname, datadir, replace_missing=True, verbose=False)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before label:  [['625' '3' '16015.0' '641' '1' '1' '0' '0']\n",
      " ['293' '2' '15902.0' '877' '1' '1' '0' '1']\n",
      " ['39' '4' '16093.0' '561' '1' '1' '0' '0']]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-933497a01ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mingestion_program\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_io\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_data/store_train.data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/FinalProject_CertBigData/starting_kit/ingestion_program/data_io.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(filename, nbr_features, verbose)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before label: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mdata_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after label: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_array'"
     ]
    }
   ],
   "source": [
    "from ingestion_program.data_io import data\n",
    "data('sample_data/store_train.data', None, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a predictive model\n",
    "We provide an example of predictive model (for classification or regression) in the `sample_code_submission/` directory. It is a quite stupid model: it makes constant predictions. Replace it with your own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model import model\n",
    "# ??model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "<h3>Create the model</h3>\n",
    "Create an instance of the model (run the constructor) \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = model()   \n",
    "trained_model_name = model_dir + dataname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Training:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = D.data['X_train']\n",
    "Y_train = D.data['Y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.2500e+02, 1.6015e+04, 6.4100e+02, 1.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00],\n",
       "       [2.9300e+02, 1.5902e+04, 8.7700e+02, 1.0000e+00, 1.0000e+00,\n",
       "        1.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00],\n",
       "       [3.9000e+01, 1.6093e+04, 5.6100e+02, 1.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00],\n",
       "       [6.7600e+02, 1.5974e+04, 1.5840e+03, 1.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00],\n",
       "       [7.0900e+02, 1.6092e+04, 1.4770e+03, 1.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00],\n",
       "       [9.1400e+02, 1.6347e+04, 8.7700e+02, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00],\n",
       "       [1.0220e+03, 1.5861e+04, 7.8900e+02, 1.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00],\n",
       "       [7.6400e+02, 1.6065e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00],\n",
       "       [9.0000e+01, 1.5742e+04, 9.4100e+02, 1.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00],\n",
       "       [8.6000e+02, 1.5999e+04, 7.1800e+02, 1.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kihansi/miniconda3/envs/cert-big-data/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train = D.data['X_train']\n",
    "Y_train = D.data['Y_train']\n",
    "\n",
    "if not(M.is_trained):               # No need to train if model already trained\n",
    "    M.fit(X_train, Y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_train = M.predict(D.data['X_train']) # Optional, not really needed to test on taining examples\n",
    "Y_hat_valid = M.predict(D.data['X_valid'])\n",
    "Y_hat_test = M.predict(D.data['X_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring the results\n",
    "### Load the challenge metric\n",
    "<b>The metric chosen for your challenge</b> is identified in the \"metric.txt\" file found in the `scoring_function/` directory. We use here the `mse_metric` metric (an example of organizer-supplied metric found in `my_metric.py`), which computes the mean-square-error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scoring metric: mse_metric\n"
     ]
    }
   ],
   "source": [
    "with open(score_dir + 'metric.txt', 'r') as f:\n",
    "    metric_name = f.readline().strip()\n",
    "import libscores, my_metric\n",
    "try:\n",
    "    scoring_function = getattr(libscores, metric_name)\n",
    "except:\n",
    "    scoring_function = getattr(my_metric, metric_name)\n",
    "print('Using scoring metric:', metric_name)\n",
    "# ??scoring_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training performance\n",
    "The participants posess target values (labels) only for training examples. We compute with the mse metric the training score, which should be zero for perfect predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score for the mse_metric metric = 135833.7550\n",
      "Ideal score for the mse_metric metric = 0.0000\n"
     ]
    }
   ],
   "source": [
    "print ('Training score for the', metric_name, 'metric = %5.4f' % scoring_function(Y_train, Y_hat_train))\n",
    "print ('Ideal score for the', metric_name, 'metric = %5.4f' % scoring_function(Y_train, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "<H3> Cross-validation performance </H3>\n",
    "The participants do not have access to the labels Y_valid and Y_test to self-assess their validation and test performances. But training performance is not a good prediction of validation or test performance. We suggest to use a cross-validation. Using cross-validation, the training data is split into multiple training/test folds, which allows participants to self-assess their model during development. <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kihansi/miniconda3/envs/cert-big-data/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 example metric =  868824.6064312891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kihansi/miniconda3/envs/cert-big-data/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 example metric =  881122.6468270642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kihansi/miniconda3/envs/cert-big-data/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 example metric =  863367.9661238351\n",
      "Average score =  871105.073127396\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from numpy import zeros, mean\n",
    "# 3-fold cross-validation\n",
    "n = 3\n",
    "kf = KFold(n_splits=n)\n",
    "kf.get_n_splits(X_train)\n",
    "i=0\n",
    "scores = zeros(n)\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    Xtr, Xva = X_train[train_index], X_train[test_index]\n",
    "    Ytr, Yva = Y_train[train_index], Y_train[test_index]\n",
    "    M = model()\n",
    "    M.fit(Xtr, Ytr)\n",
    "    Yhat = M.predict(Xva)\n",
    "    scores[i] = scoring_function(Yva, Yhat)\n",
    "    print ('Fold', i+1, 'example metric = ', scores[i])\n",
    "    i=i+1\n",
    "print ('Average score = ', mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Making a submission\n",
    "\n",
    "## Unit testing\n",
    "\n",
    "A possibility to prepare a submission is the following one.  Modify the file <code>model.py</code> in the <code>sample_code_submission/</code> directory, then run this test to make sure everything works fine. The results of this program will be used on the server to test your submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdir = 'sample_result_submission'     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using input_dir: /home/kihansi/Projects/FinalProject_CertBigData/starting_kit/sample_data\n",
      "Using output_dir: /home/kihansi/Projects/FinalProject_CertBigData/starting_kit/sample_result_submission\n",
      "Using program_dir: /home/kihansi/Projects/FinalProject_CertBigData/starting_kit/ingestion_program\n",
      "Using submission_dir: /home/kihansi/Projects/FinalProject_CertBigData/starting_kit/sample_code_submission\n",
      "Using TensorFlow backend.\n",
      "\n",
      "========== Ingestion program version 6 ==========\n",
      "\n",
      "************************************************\n",
      "******** Processing dataset Store ********\n",
      "************************************************\n",
      "========= Reading and converting data ==========\n",
      "Info file found : /home/kihansi/Projects/FinalProject_CertBigData/starting_kit/sample_data/store_public.info\n",
      "========= Reading /home/kihansi/Projects/FinalProject_CertBigData/starting_kit/sample_data/store_feat.type\n",
      "[+] Success in  0.00 sec\n",
      "========= Reading /home/kihansi/Projects/FinalProject_CertBigData/starting_kit/sample_data/store_train.data\n",
      "[['625' '3' '2013-11-06' ... '1' '0' '0']\n",
      " ['293' '2' '2013-07-16' ... '1' '0' '1']\n",
      " ['39' '4' '2014-01-23' ... '1' '0' '0']\n",
      " ...\n",
      " ['135' '6' '2015-06-20' ... '0' '0' '0']\n",
      " ['810' '1' '2014-08-18' ... '1' '0' '1']\n",
      " ['592' '1' '2013-03-18' ... '1' '0' '0']]\n",
      "Reading /home/kihansi/Projects/FinalProject_CertBigData/starting_kit/sample_data/store_train.data...\n",
      "Converting /home/kihansi/Projects/FinalProject_CertBigData/starting_kit/sample_data/store_train.data to correct array...\n",
      "Replace missing values by 0 (slow, sorry)\n",
      "[+] Success in 10.06 sec\n",
      "========= Reading /home/kihansi/Projects/FinalProject_CertBigData/starting_kit/sample_data/store_train.solution\n",
      "[+] Success in  0.94 sec\n",
      "========= Reading /home/kihansi/Projects/FinalProject_CertBigData/starting_kit/sample_data/store_valid.data\n",
      "[['731' '1' '2014-02-24' ... '0' '0' '0']\n",
      " ['293' '4' '2013-01-03' ... '0' '0' '1']\n",
      " ['650' '1' '2013-12-30' ... '0' '0' '1']\n",
      " ...\n",
      " ['991' '5' '2013-01-11' ... '1' '0' '0']\n",
      " ['1018' '4' '2015-02-12' ... '0' '0' '0']\n",
      " ['768' '6' '2013-08-10' ... '0' '0' '0']]\n",
      "Reading /home/kihansi/Projects/FinalProject_CertBigData/starting_kit/sample_data/store_valid.data...\n",
      "Converting /home/kihansi/Projects/FinalProject_CertBigData/starting_kit/sample_data/store_valid.data to correct array...\n",
      "Replace missing values by 0 (slow, sorry)\n",
      "[+] Success in  1.40 sec\n",
      "========= Reading /home/kihansi/Projects/FinalProject_CertBigData/starting_kit/sample_data/store_test.data\n",
      "[['249' '5' '2014-12-19' ... '1' '0' '0']\n",
      " ['190' '4' '2013-02-28' ... '0' '0' '0']\n",
      " ['850' '3' '2013-06-05' ... '1' '0' '0']\n",
      " ...\n",
      " ['37' '2' '2014-03-11' ... '0' '0' '0']\n",
      " ['778' '3' '2015-01-14' ... '1' '0' '0']\n",
      " ['745' '6' '2014-09-13' ... '0' '0' '0']]\n",
      "Reading /home/kihansi/Projects/FinalProject_CertBigData/starting_kit/sample_data/store_test.data...\n",
      "Converting /home/kihansi/Projects/FinalProject_CertBigData/starting_kit/sample_data/store_test.data to correct array...\n",
      "Replace missing values by 0 (slow, sorry)\n",
      "[+] Success in  2.97 sec\n",
      "DataManager : store\n",
      "info:\n",
      "\tusage = Sample dataset data\n",
      "\tname = wavestone\n",
      "\ttask = regression\n",
      "\ttarget_type = Numerical\n",
      "\tfeat_type = Numerical, String\n",
      "\tmetric = bac_metric\n",
      "\ttime_budget = 1200\n",
      "\tfeat_num = 8\n",
      "\ttarget_num = 1\n",
      "\tlabel_num = 1\n",
      "\ttrain_num = 712046\n",
      "\tvalid_num = 101722\n",
      "\ttest_num = 203441\n",
      "\thas_categorical = 0\n",
      "\thas_missing = 1\n",
      "\tis_sparse = 0\n",
      "\tformat = dense\n",
      "data:\n",
      "\tX_train = array(50000, 17)\n",
      "\tY_train = array(50000,)\n",
      "\tX_valid = array(101720, 17)\n",
      "\tX_test = array(203444, 17)\n",
      "feat_type:\tarray(8,)\n",
      "feat_idx:\tarray(17,)\n",
      "\n",
      "[+] Size of uploaded data  56.00 bytes\n",
      "[+] Cumulated time budget (all tasks so far)  1200.00 sec\n",
      "[+] Time budget for this task 1200.00 sec\n",
      "[+] Remaining time after reading data 1184.59 sec\n",
      "======== Creating model ==========\n",
      "**********************************************************\n",
      "****** Attempting to reload model to avoid training ******\n",
      "**********************************************************\n",
      "======== Trained model not found, proceeding to train!\n",
      "/home/kihansi/miniconda3/envs/cert-big-data/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "[+] Fitting success, time spent so far  1.14 sec\n",
      "======== Saving model to: /home/kihansi/Projects/FinalProject_CertBigData/starting_kit/sample_result_submission\n",
      "[+] Success!\n",
      "[+] Prediction success, time spent so far  1.75 sec\n",
      "======== Saving results to: /home/kihansi/Projects/FinalProject_CertBigData/starting_kit/sample_result_submission\n",
      "[+] Results saved, time spent so far  2.10 sec\n",
      "[+] End cycle, time left 1197.90 sec\n",
      "[+] Done\n",
      "[+] Overall time spent 18.78 sec ::  Overall time budget 1200.00 sec\n"
     ]
    }
   ],
   "source": [
    "!python $problem_dir/ingestion.py $datadir $outdir $problem_dir $model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preparing the submission\n",
    "\n",
    "To prepare the submission, you can run the command in the previous cell on the appropriate data (testing or validation data), and then zip the contents of `sample_result_submission/` (without the directory, and remember to remove the examples that are already there).\n",
    "\n",
    "However, it is not necessary to run the previous code to prepare a submission. The site for the submission checks the predicted results against the true labels, through the scoring function. It accepts any zip file conatining files with extension '.predict'. It is important however that the name of the file matches that of the data. Example: to submit labels for store_train.data, the zip file has to contain a file named store_train.predict, with the same structure of the ones in `sample_result_submission/`\n",
    "<b><span style=\"color:red\">Do NOT zip the data with your submissions</span></b>. After the submission you are given your score. If the result is close to zero, the prediction is good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
